% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/gwet_agree.coeff3.dist.r
\name{krippen.alpha.dist}
\alias{krippen.alpha.dist}
\title{Krippendorff's alpha coefficient}
\usage{
krippen.alpha.dist(ratings, weights = "unweighted", conflev = 0.95,
  N = Inf, print = TRUE)
}
\arguments{
\item{ratings}{an \code{n x q} matrix showing the number of raters by
subject and category where \code{n} is the number of subjects and \code{q}
is the number of categories}

\item{weights}{optional weighting}

\item{conflev}{confidence level}

\item{N}{used as denominator in finite population correction}

\item{print}{logical; if \code{TRUE}, prints a summary of the agreement}
}
\description{
Computes Krippendorff's alpha coefficient and standard error for multiple 
raters when data is an \code{n x q} matrix representing the distribution of
raters be subject and by category.
}
\details{
A typical entry associated with a subject and a category, represents the 
number of raters who classified the subject into the specified category. 
Excludes all subjects that are not rated by any rater.

The algorithm used to compute Krippendorff's alpha is very different from 
anything that was published on this topic. Instead, it follows the equations
presented by K. Gwet (2010).
}
\references{
Gwet, K. (2012). Handbook of Inter-Rater Reliability: the Definitive Guide 
to Measuring the Extent of Agreement among Multiple Raters, 3rd Edition.
Advanced Analytics, LLC; 3rd edition (March 2, 2012).

Krippendorff (1970). "Bivariate agreement coefficients for reliability of 
data." Sociological Methodology, 2, 139-150.

Krippendorff (1980). Content analysis: An introduction to its methodology 
(2nd ed.), New-bury Park, CA: Sage.
}
\author{
Kilem L. Gwet
}
